{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4FJAbPwHv_1"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5q4Ajw8zPv9e",
        "outputId": "9e7feddf-9242-462c-fd41-6a9c408c1211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Unnamed: 0  Unnamed..0  problem_log_id  problem_id  assignment_log_id  \\\n",
            "0             1        3555          271247     1600503              41158   \n",
            "1             2         225       152647500     1295424           19868375   \n",
            "2             3        4722        98634597     1740550           12991684   \n",
            "3             4        2306         7530734     1525795            1018873   \n",
            "4             5         287       152670590     1295424           19871673   \n",
            "..          ...         ...             ...         ...                ...   \n",
            "195         196        3680       105224895     1601931           13855808   \n",
            "196         197        4087        72189588     1619629            9452036   \n",
            "197         198        3037        58061482     1577424            7528543   \n",
            "198         199        4950        69713330     1879410            9117664   \n",
            "199         200        1069        88955918     1477552           11702015   \n",
            "\n",
            "     assignment_xid  assignment_id  teacher_xid  \\\n",
            "0              9372           3178         7629   \n",
            "1           3245282        1717394         7629   \n",
            "2           2338716        1107560         8926   \n",
            "3            206643          79440         7629   \n",
            "4           3245574        1717595         7629   \n",
            "..              ...            ...          ...   \n",
            "195         2481326        1219413       350841   \n",
            "196         1986922         848598         8926   \n",
            "197         1765128         703301         7629   \n",
            "198         1966177         834916         7629   \n",
            "199         2221912        1018602         8926   \n",
            "\n",
            "                                       assignment_name  sequence_id  ...  \\\n",
            "0                                   Warm Up March 28th       983700  ...   \n",
            "1                                         Warm Up 3/31      1458840  ...   \n",
            "2    8.3 - Lesson 2 Practice: Graphs of Proportiona...       805623  ...   \n",
            "3                                          WarmUp 2/24      1062454  ...   \n",
            "4                                         Warm Up 3/31      1458840  ...   \n",
            "..                                                 ...          ...  ...   \n",
            "195  Cool-Downs---7.6 Lesson 1: Relationships Betwe...       900153  ...   \n",
            "196  Grade 8 Unit 2 Lesson 1 Cooldown Projecting an...       904208  ...   \n",
            "197          Warm Up 10/9-DO NOT COMPLETE BEFORE CLASS      1219687  ...   \n",
            "198                                       Warm Up 11/4      1249525  ...   \n",
            "199    8.2 - Lesson 10 Practice: Meet Slope (8.EE.B.6)       803289  ...   \n",
            "\n",
            "    continuous_score score                                    teacher_comment  \\\n",
            "0                0.0     0  What are you multiplying by? What is \"the answ...   \n",
            "1                0.0     0  Saleem is incorrect because the 1st is 1440 an...   \n",
            "2                0.0     0  Please do not copy and paste definitions from ...   \n",
            "3                0.0     0  This question wants you to explain or show you...   \n",
            "4                0.0     0  Saleem is incorrect because the 1st is 1440 an...   \n",
            "..               ...   ...                                                ...   \n",
            "195              1.0     4  There is a pattern, for example, 10 ounces of ...   \n",
            "196              1.0     4                                           Perfect!   \n",
            "197              1.0     4                                         Great job!   \n",
            "198              1.0     4                                         Great job!   \n",
            "199              1.0     4                                              Good.   \n",
            "\n",
            "    attempt_count hint_count  rownum  word_count  char_count  num_count  \\\n",
            "0               1          0      56          25         118          3   \n",
            "1               1          0      26          17          78          4   \n",
            "2               1          0      23          44         243          0   \n",
            "3               1          0       7          11          50          0   \n",
            "4               1          0      88          18          73          4   \n",
            "..            ...        ...     ...         ...         ...        ...   \n",
            "195             1          0      81          28         118         11   \n",
            "196             1          0      88          23         121          0   \n",
            "197             1          0      38          45         233         16   \n",
            "198             1          0      51          24         115         11   \n",
            "199             1          0      70          24         115          3   \n",
            "\n",
            "    symbol_count  \n",
            "0              1  \n",
            "1              0  \n",
            "2              5  \n",
            "3              1  \n",
            "4              1  \n",
            "..           ...  \n",
            "195            2  \n",
            "196            2  \n",
            "197            5  \n",
            "198            2  \n",
            "199            1  \n",
            "\n",
            "[200 rows x 33 columns]\n",
            "Processing rows 0 to 14\n",
            "Processed rows 0 to 14\n",
            "Processing rows 15 to 29\n",
            "Processed rows 15 to 29\n",
            "Processing rows 30 to 44\n",
            "Processed rows 30 to 44\n",
            "Processing rows 45 to 59\n",
            "Processed rows 45 to 59\n",
            "Processing rows 60 to 74\n",
            "Processed rows 60 to 74\n",
            "Processing rows 75 to 89\n",
            "Processed rows 75 to 89\n",
            "Processing rows 90 to 104\n",
            "Processed rows 90 to 104\n",
            "Processing rows 105 to 119\n",
            "Processed rows 105 to 119\n",
            "Processing rows 120 to 134\n",
            "Processed rows 120 to 134\n",
            "Processing rows 135 to 149\n",
            "Processed rows 135 to 149\n",
            "Processing rows 150 to 164\n",
            "Processed rows 150 to 164\n",
            "Processing rows 165 to 179\n",
            "Processed rows 165 to 179\n",
            "Processing rows 180 to 194\n",
            "Processed rows 180 to 194\n",
            "Processing rows 195 to 199\n",
            "Processed rows 195 to 199\n",
            "Processing complete.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure the API key\n",
        "genai.configure(api_key=\"AIzaSyDheKgFc7-eqi2p3YdQeTmtUwfhOzLfLVc\")\n",
        "\n",
        "# Define the model configuration\n",
        "generation_config = {\n",
        "    \"temperature\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 40,\n",
        "    \"max_output_tokens\": 100,\n",
        "    \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "# Initialize the generative AI model\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generation_config=generation_config,\n",
        ")\n",
        "\n",
        "# Start a chat session\n",
        "chat_session = model.start_chat(history=[])\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv('df_subset.csv', encoding='utf-8')\n",
        "print(df)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 15\n",
        "\n",
        "# Iterate through the dataset in batches\n",
        "total_rows = len(df)\n",
        "for start_idx in range(0, total_rows, batch_size):\n",
        "    end_idx = min(start_idx + batch_size, total_rows)  # Ensure not to exceed total rows\n",
        "    print(f\"Processing rows {start_idx} to {end_idx - 1}\")\n",
        "\n",
        "    for index in range(start_idx, end_idx):\n",
        "        row = df.loc[index]\n",
        "        question = row['problem_body']\n",
        "        stu_response = row['answer_text']\n",
        "\n",
        "        # Create the prompt\n",
        "        prompt = (\n",
        "            f\"Here is a student's response to an open-ended question:\\n\"\n",
        "            f\"Question: {question}\\n\"\n",
        "            f\"Student's response: {stu_response}.\\n\"\n",
        "            \"Score the student's response on a scale of 0 to 4, only provide a score.\"\n",
        "        )\n",
        "\n",
        "        # Send the prompt to the model\n",
        "        try:\n",
        "            response = chat_session.send_message(prompt)\n",
        "            response_text = response.text\n",
        "        except Exception as e:\n",
        "            response_text = f\"Error: {str(e)}\"\n",
        "\n",
        "        # Update the DataFrame with results\n",
        "        df.loc[index, 'Prompt'] = prompt\n",
        "        df.loc[index, 'Gemini_Response'] = response_text\n",
        "\n",
        "    # Save intermediate results to avoid data loss\n",
        "    df.to_csv('GeminiAnonOutput.csv', index=False)\n",
        "    print(f\"Processed rows {start_idx} to {end_idx - 1}\")\n",
        "\n",
        "    # Pause between batches if necessary\n",
        "    time.sleep(120)  # Adjust based on your system's constraints\n",
        "\n",
        "print(\"Processing complete.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}